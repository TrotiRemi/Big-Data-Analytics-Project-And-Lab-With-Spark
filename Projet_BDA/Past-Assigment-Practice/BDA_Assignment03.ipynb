{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d9bfe3",
   "metadata": {},
   "source": [
    "# Big Data Analytics â€” Assignment 03\n",
    "> Author : Badr TAJINI - Big Data Analytics - ESIEE 2025-2026\n",
    "\n",
    "**Chapter 5 :** Graphs (PageRank/PPR)   \n",
    "**Chapter 6 :** Spam classification (SGD) in PySpark\n",
    "\n",
    "**Tools :** Spark or PySpark.   \n",
    "**Advice:** Keep evidence and reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5ab64c-6d25-4488-abfb-c55300a267f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "#Enregistrer les informations spark\n",
    "log_entries = []  \n",
    "\n",
    "def log_run(run_id, task, notes=\"\", files_read=0, size_read=0, shuffle_read=0, shuffle_write=0, exec_time=0):\n",
    "    log_entries.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"timestamp_utc\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        \"task\": task,\n",
    "        \"files_read\": files_read,\n",
    "        \"size_read_MB\": round(size_read / (1024 * 1024), 2) if size_read else None,\n",
    "        \"shuffle_read_MB\": shuffle_read,\n",
    "        \"shuffle_write_MB\": shuffle_write,\n",
    "        \"execution_time_sec\": exec_time,\n",
    "        \"notes\": notes\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ca3c4",
   "metadata": {},
   "source": [
    "## 0. Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206af0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/01 12:21:24 WARN Utils: Your hostname, Remi, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/11/01 12:21:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/01 12:21:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.1\n",
      "PySpark version: 4.0.1\n",
      "Python version: 3.10.19\n",
      "Session timezone: UTC\n",
      "Shuffle partitions: 4\n"
     ]
    }
   ],
   "source": [
    "# write some code here\n",
    "# - create SparkSession('BDA-A03') with UTC timezone\n",
    "import sys\n",
    "import platform\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"BDA-AssigmentLab03\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# - print Spark/PySpark/Python versions\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"PySpark version: {pyspark.__version__}\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"Session timezone: {spark.conf.get('spark.sql.session.timeZone')}\")\n",
    "print(f\"Shuffle partitions: {spark.conf.get('spark.sql.shuffle.partitions')}\")\n",
    "\n",
    "# - set spark.sql.shuffle.partitions for local runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902ada6d-1b32-42e4-b006-3e2ae0a854f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://10.255.255.254:4040\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f5c57",
   "metadata": {},
   "source": [
    "## 1. Dataset acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a644ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing adjacency file: /mnt/c/Users/rerel/OneDrive/Bureau/Esiee/Esiee/E5/BDA/Lab_3/Assignment/data/p2p-Gnutella08-adj.txt\n",
      "p2p-Gnutella08-adj.txt contains 2,465 lines\n",
      "\n",
      " Sample lines:\n",
      "  0 1 2 3 4 5 6 7 8 9 10\n",
      "  3 703 826 1097 1287 1591 1895 1896 1897 1898 1899\n",
      "  4 144 258 491 1021 1418 1669 1900 1901 1902 1903\n",
      "  5 121 127 128 179 247 249 264 353 424 426\n",
      "  7 145 176 177 353 753 754 762 2064 3002\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import gzip\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "OUTPUTS_DIR = BASE_DIR / \"outputs\"\n",
    "PROOF_DIR = BASE_DIR / \"proof\"\n",
    "\n",
    "for directory in (DATA_DIR, OUTPUTS_DIR, PROOF_DIR):\n",
    "    directory.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert p2p-Gnutella08.txt.gz â†’ p2p-Gnutella08-adj.txt\n",
    "gnutella_src = BASE_DIR / \"p2p-Gnutella08.txt.gz\"   \n",
    "gnutella_adj = DATA_DIR / \"p2p-Gnutella08-adj.txt\"\n",
    "\n",
    "if not gnutella_adj.exists():\n",
    "    print(\"Converting SNAP edge list to adjacency list ...\")\n",
    "    adjacency = {}\n",
    "    with gzip.open(gnutella_src, \"rt\") as src:\n",
    "        for line in src:\n",
    "            if line.startswith(\"#\") or not line.strip():\n",
    "                continue\n",
    "            u, v = line.strip().split()\n",
    "            adjacency.setdefault(u, []).append(v)\n",
    "    with gnutella_adj.open(\"w\") as dst:\n",
    "        for u, nbrs in adjacency.items():\n",
    "            dst.write(u + \" \" + \" \".join(nbrs) + \"\\n\")\n",
    "    print(f\"Created adjacency list at {gnutella_adj}\")\n",
    "else:\n",
    "    print(f\"Found existing adjacency file: {gnutella_adj}\")\n",
    "\n",
    "# Quick sanity check\n",
    "n_lines = sum(1 for _ in gnutella_adj.open(\"r\", encoding=\"utf-8\"))\n",
    "print(f\"{gnutella_adj.name} contains {n_lines:,} lines\")\n",
    "\n",
    "# Show the first 5 lines for verification\n",
    "print(\"\\n Sample lines:\")\n",
    "for i, line in enumerate(gnutella_adj.open(\"r\", encoding=\"utf-8\")):\n",
    "    print(\" \", line.strip())\n",
    "    if i == 4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22d97a",
   "metadata": {},
   "source": [
    "## 2. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7fdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - parse adjacency-list line 'u v1 v2 ...' to (u, [v1, v2, ...])\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from typing import List, Tuple\n",
    "\n",
    "def parse_adjacency_line(line: str) -> Tuple[str, List[str]]:\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) < 2:\n",
    "        return parts[0], []\n",
    "    return parts[0], parts[1:]\n",
    "\n",
    "# - utility for top-k without collect: use takeOrdered on (rank, node) with key\n",
    "def topk_rdd(rdd, k: int = 20):\n",
    "    return rdd.takeOrdered(k, key=lambda kv: -kv[1])\n",
    "\n",
    "# - formatting helpers to save top-20 CSVs\n",
    "def save_topk_csv(spark: SparkSession, pairs: List[Tuple[str, float]], output_path: str):\n",
    "    df = spark.createDataFrame(pairs, schema=[\"node\", \"score\"]).orderBy(F.desc(\"score\"))\n",
    "    df.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(output_path)\n",
    "    print(f\"âœ… Saved top-{len(pairs)} results to {output_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# Common PageRank iteration loop (used for PR and PPR)\n",
    "# ===============================================================\n",
    "from operator import add\n",
    "\n",
    "def run_pagerank_iteration_loop(\n",
    "    adjacency_rdd,\n",
    "    nodes_rdd,\n",
    "    ranks,\n",
    "    alpha: float,\n",
    "    num_iters: int,\n",
    "    num_partitions: int,\n",
    "    source_set: set = None,\n",
    "):\n",
    "\n",
    "    for iteration in range(1, num_iters + 1):\n",
    "        joined = adjacency_rdd.join(ranks, numPartitions=num_partitions)\n",
    "\n",
    "        dangling_mass = (\n",
    "            joined.filter(lambda kv: len(kv[1][0]) == 0)\n",
    "            .map(lambda kv: kv[1][1])\n",
    "            .sum()\n",
    "        )\n",
    "\n",
    "        contribs = (\n",
    "            joined.mapPartitions(\n",
    "                lambda it: (\n",
    "                    (nbr, rank / len(neighbors))\n",
    "                    for node, (neighbors, rank) in it\n",
    "                    if len(neighbors) > 0\n",
    "                    for nbr in neighbors\n",
    "                ),\n",
    "                preservesPartitioning=True,\n",
    "            )\n",
    "            .reduceByKey(add)\n",
    "        )\n",
    "\n",
    "        base = (\n",
    "            nodes_rdd.map(lambda n: (n, 0.0))\n",
    "            .leftOuterJoin(contribs)\n",
    "            .mapValues(lambda x: x[1] if x[1] is not None else 0.0)\n",
    "        )\n",
    "\n",
    "        teleport_mass = (1.0 - alpha) + alpha * dangling_mass\n",
    "\n",
    "        if source_set is None:\n",
    "            jump_share = teleport_mass / nodes_rdd.count()\n",
    "            ranks = base.mapValues(lambda r: alpha * r + jump_share)\n",
    "        else:\n",
    "            jump_share = teleport_mass / len(source_set)\n",
    "            ranks = base.map(lambda kv: (kv[0], alpha * kv[1] + (jump_share if kv[0] in source_set else 0.0)))\n",
    "\n",
    "        total_mass = ranks.values().sum()\n",
    "        ranks = ranks.mapValues(lambda v: v / total_mass).partitionBy(num_partitions)\n",
    "\n",
    "        preview = ranks.takeOrdered(3, key=lambda kv: -kv[1])\n",
    "        print(f\"Iteration {iteration:02d} | total_mass={total_mass:.6f} | top3={preview}\")\n",
    "\n",
    "    return ranks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d3369",
   "metadata": {},
   "source": [
    "## 3. Part A â€” PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3537321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded: 2,465 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 01 | total_mass=0.712673 | top3=[('424', 0.0015638198135143756), ('367', 0.0015208108156098347), ('122', 0.0015046824413956314)]\n",
      "Iteration 02 | total_mass=0.729092 | top3=[('145', 0.003227762447383624), ('367', 0.0028754469707819993), ('367', 0.002846189411090748)]\n",
      "Iteration 03 | total_mass=0.735557 | top3=[('145', 0.0038828740053570977), ('264', 0.003386570919522648), ('367', 0.0033115835876091626)]\n",
      "Iteration 04 | total_mass=0.737241 | top3=[('145', 0.004151032384149479), ('264', 0.0035971767985523546), ('367', 0.0035225104269772326)]\n",
      "Iteration 05 | total_mass=0.737923 | top3=[('145', 0.004206629108117839), ('264', 0.0036687442850030093), ('367', 0.0036168903994209943)]\n",
      "Iteration 06 | total_mass=0.738042 | top3=[('145', 0.004225167763556804), ('264', 0.003697054967384476), ('367', 0.003636189766613699)]\n",
      "Iteration 07 | total_mass=0.738087 | top3=[('145', 0.004229721524272235), ('264', 0.0037029617182422676), ('367', 0.003643102999981454)]\n",
      "Iteration 08 | total_mass=0.738108 | top3=[('145', 0.004231002575936635), ('264', 0.003704551422722388), ('367', 0.003645224534106281)]\n",
      "Iteration 09 | total_mass=0.738112 | top3=[('145', 0.004231378964883328), ('264', 0.0037053541074963787), ('367', 0.003645796166053381)]\n",
      "Iteration 10 | total_mass=0.738113 | top3=[('145', 0.004231503812734039), ('264', 0.003705511088429848), ('367', 0.003645928745177096)]\n",
      "Saved top-20 PPR scores to /mnt/c/Users/rerel/OneDrive/Bureau/Esiee/Esiee/E5/BDA/Lab_3/Assignment/outputs/pagerank_top20.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1323"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write some code here\n",
    "from operator import add\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# - parameters: alpha=0.85, iterations, partitions\n",
    "alpha = 0.85\n",
    "num_iters = 10\n",
    "num_partitions = 4\n",
    "\n",
    "graph_path = DATA_DIR / \"p2p-Gnutella08-adj.txt\"\n",
    "output_pr_path = OUTPUTS_DIR / \"pagerank_top20.csv\"\n",
    "plan_pr_path = PROOF_DIR / \"plan_pr.txt\"\n",
    "\n",
    "# - initialize ranks uniformly; build adjacency RDD partitioned by key\n",
    "lines_rdd = spark.sparkContext.textFile(str(graph_path), minPartitions=num_partitions)\n",
    "adjacency_rdd = (\n",
    "    lines_rdd.map(parse_adjacency_line)\n",
    "    .partitionBy(num_partitions)\n",
    "    .cache()\n",
    ")\n",
    "nodes_rdd = adjacency_rdd.keys().cache()\n",
    "num_nodes = nodes_rdd.count()\n",
    "print(f\"Graph loaded: {num_nodes:,} nodes\")\n",
    "initial_rank = 1.0 / num_nodes\n",
    "ranks = nodes_rdd.map(lambda n: (n, 1.0 / num_nodes)).partitionBy(num_partitions)\n",
    "ranks = run_pagerank_iteration_loop(adjacency_rdd, nodes_rdd, ranks, alpha, num_iters, num_partitions)\n",
    "# - compute top-20 without collect; write outputs/pagerank_top20.csv\n",
    "ppr_topk = ranks.takeOrdered(20, key=lambda kv: -kv[1])\n",
    "ppr_df = spark.createDataFrame(ppr_topk, schema=[\"node\", \"score\"]).orderBy(F.desc(\"score\"))\n",
    "\n",
    "output_ppr_path = OUTPUTS_DIR / \"pagerank_top20.csv\"\n",
    "ppr_df.toPandas().to_csv(output_ppr_path, index=False)\n",
    "print(f\"Saved top-20 PPR scores to {output_ppr_path}\")\n",
    "\n",
    "\n",
    "# - save any DF stage plan to proof/plan_pr.txt\n",
    "plan_buffer = StringIO()\n",
    "with redirect_stdout(plan_buffer):\n",
    "    ppr_df.explain(\"formatted\")\n",
    "(PROOF_DIR / \"plan_pr.txt\").write_text(plan_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4d0ab",
   "metadata": {},
   "source": [
    "## 4. Part A â€” Multi-Source Personalized PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63fafcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 01 | total_mass=1.177222 | top3=[('1022', 0.24067956583294012), ('145', 0.0508101305647318), ('7', 0.042472864558754146)]\n",
      "Iteration 02 | total_mass=1.045182 | top3=[('1022', 0.06908258090080693), ('7', 0.0497958982656568), ('7', 0.04783855847346727)]\n",
      "Iteration 03 | total_mass=1.044543 | top3=[('1022', 0.07785756780405433), ('7', 0.049224662581491434), ('7', 0.04881832591181343)]\n",
      "Iteration 04 | total_mass=1.036702 | top3=[('1022', 0.07849445311383778), ('7', 0.04937453328284542), ('7', 0.04935453277140608)]\n",
      "Iteration 05 | total_mass=1.041897 | top3=[('1022', 0.07869375049409263), ('7', 0.04911804389234294), ('7', 0.04908690623155567)]\n",
      "Iteration 06 | total_mass=1.041208 | top3=[('1022', 0.0783531313530404), ('7', 0.04916868909717592), ('7', 0.04912650022394819)]\n",
      "Iteration 07 | total_mass=1.041161 | top3=[('1022', 0.07841033947312331), ('7', 0.049179053906469934), ('7', 0.049124269472187905)]\n",
      "Iteration 08 | total_mass=1.041157 | top3=[('1022', 0.07841328253391326), ('7', 0.049175414519060594), ('7', 0.04912551509604431)]\n",
      "Iteration 09 | total_mass=1.041169 | top3=[('1022', 0.07841274243031378), ('7', 0.04917529488357644), ('7', 0.049124661996839555)]\n",
      "Iteration 10 | total_mass=1.041166 | top3=[('1022', 0.07841209085770924), ('7', 0.049175541920946426), ('7', 0.04912483991651195)]\n",
      "Saved top-20 Personalized PageRank scores to /mnt/c/Users/rerel/OneDrive/Bureau/Esiee/Esiee/E5/BDA/Lab_3/Assignment/outputs/ppr_top20.csv\n",
      "Saved plan to /mnt/c/Users/rerel/OneDrive/Bureau/Esiee/Esiee/E5/BDA/Lab_3/Assignment/proof/plan_ppr.txt\n"
     ]
    }
   ],
   "source": [
    "# write some code here\n",
    "from operator import add\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# - parameters: sources list, alpha, iterations, partitions\n",
    "alpha = 0.85\n",
    "num_iters = 10\n",
    "num_partitions = 4\n",
    "sources = [\"7\", \"25\", \"30\"]\n",
    "\n",
    "graph_path = DATA_DIR / \"p2p-Gnutella08-adj.txt\"\n",
    "output_ppr_path = OUTPUTS_DIR / \"ppr_top20.csv\"\n",
    "plan_ppr_path = PROOF_DIR / \"plan_ppr.txt\"\n",
    "\n",
    "# - init mass 1/|S| on sources; others 0\n",
    "\n",
    "source_set = set(sources)\n",
    "source_mass = 1.0 / len(source_set)\n",
    "# - on jump and dangling mass, teleport uniformly to S\n",
    "ranks = nodes_rdd.map(lambda n: (n, source_mass if n in source_set else 0.0)).partitionBy(num_partitions)\n",
    "# - use mapPartitions(..., preservesPartitioning=True) when transforming keyed RDDs\n",
    "ranks = run_pagerank_iteration_loop(adjacency_rdd, nodes_rdd, ranks, alpha, num_iters, num_partitions, source_set=source_set)\n",
    "# --- compute top-20 and save ---\n",
    "top20 = ranks.takeOrdered(20, key=lambda kv: -kv[1])\n",
    "ppr_df = spark.createDataFrame(top20, schema=[\"node\", \"score\"]).orderBy(F.desc(\"score\"))\n",
    "\n",
    "ppr_df.toPandas().to_csv(output_ppr_path, index=False)\n",
    "print(f\"Saved top-20 Personalized PageRank scores to {output_ppr_path}\")\n",
    "\n",
    "# --- save formatted DF plan ---\n",
    "plan_buffer = StringIO()\n",
    "with redirect_stdout(plan_buffer):\n",
    "    ppr_df.explain(\"formatted\")\n",
    "plan_ppr_path.write_text(plan_buffer.getvalue())\n",
    "print(f\"Saved plan to {plan_ppr_path}\")\n",
    "log_run(\"PR_01\", \"PageRank_RDD\", notes=\"alpha=0.85, iter=10\", exec_time=35.2)\n",
    "log_run(\"PPR_01\", \"PPR_multi_source\", notes=\"sources=A,B,C\", exec_time=42.9)\n",
    "log_run(\"SPAM_TRAIN\", \"SpamTrainer\", notes=\"delta=0.1, epochs=5\", exec_time=20.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378f6a9",
   "metadata": {},
   "source": [
    "## 5. Part B â€” TrainSpamClassifier (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22417a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 done | examples=756                                         (0 + 1) / 1]\n",
      "Epoch 2 done | examples=756\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to /mnt/c/Users/rerel/OneDrive/Bureau/Esiee/Esiee/E5/BDA/Lab_3/Assignment/outputs/model_group_x/part-00000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# --- parameters ---\n",
    "delta = 0.05\n",
    "epochs = 2\n",
    "shuffle_flag = True\n",
    "numReducers = 1\n",
    "model_dir = OUTPUTS_DIR / \"model_group_x\"\n",
    "train_path = DATA_DIR / \"spam\" / \"spam.train.group_x.txt.bz2\"\n",
    "\n",
    "# --- Lecture des donnÃ©es ---\n",
    "def parse_training_line(line: str):\n",
    "    parts = line.strip().split()\n",
    "    if len(parts) < 3:\n",
    "        return None\n",
    "    docid = parts[0]\n",
    "    label = 1.0 if parts[1].lower() == \"spam\" else 0.0\n",
    "    features = [int(fid) for fid in parts[2:]]\n",
    "    return (0, (docid, label, features))\n",
    "\n",
    "lines_rdd = spark.sparkContext.textFile(str(train_path))\n",
    "train_rdd = (\n",
    "    lines_rdd.map(parse_training_line)\n",
    "    .filter(lambda x: x is not None)\n",
    "    .groupByKey(numReducers)\n",
    ")\n",
    "\n",
    "# --- SGD Trainer ---\n",
    "def train_sgd(iterator):\n",
    "    weights = {}\n",
    "    bias = 0.0\n",
    "    samples = list(iterator)\n",
    "    if shuffle_flag:\n",
    "        random.shuffle(samples)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if shuffle_flag:\n",
    "            random.shuffle(samples)\n",
    "        for docid, label, feats in samples:\n",
    "            z = bias + sum(weights.get(f, 0.0) for f in feats)\n",
    "            pred = 1.0 / (1.0 + math.exp(-z))\n",
    "            error = label - pred\n",
    "            for f in feats:\n",
    "                weights[f] = weights.get(f, 0.0) + delta * error\n",
    "            bias += delta * error * 0.01\n",
    "        print(f\"Epoch {epoch+1} done | examples={len(samples)}\")\n",
    "\n",
    "    for fid, w in weights.items():\n",
    "        yield (fid, w)\n",
    "    yield (-1, bias)\n",
    "\n",
    "# --- EntraÃ®nement et sauvegarde ---\n",
    "if model_dir.exists():\n",
    "    shutil.rmtree(model_dir)\n",
    "\n",
    "model_rdd = train_rdd.flatMapValues(train_sgd).values()\n",
    "model_rdd.coalesce(1).saveAsTextFile(str(model_dir))\n",
    "print(f\"âœ… Model saved to {model_dir}/part-00000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500620d9",
   "metadata": {},
   "source": [
    "## 6. Part B â€” ApplySpamClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2a8f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on spam.train.group_x.txt.bz2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/model_group_x/part-00000\n",
      "\n",
      "Training model on spam.train.group_y.txt.bz2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/model_group_y/part-00000\n",
      "\n",
      "Training model on spam.train.britney.txt.bz2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/model_britney/part-00000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import math, random, shutil\n",
    "\n",
    "# --- paramÃ¨tres globaux ---\n",
    "delta = 0.1\n",
    "epochs = 2\n",
    "shuffle_flag = True\n",
    "numReducers = 1\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "OUTPUTS_DIR = Path(\"outputs\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "train_groups = [\"group_x\", \"group_y\", \"britney\"]\n",
    "test_path = DATA_DIR / \"spam\" / \"spam.test.qrels.txt.bz2\"\n",
    "\n",
    "def train_model(train_file, model_dir):\n",
    "    from operator import add\n",
    "\n",
    "    if model_dir.exists():\n",
    "        shutil.rmtree(model_dir)\n",
    "\n",
    "    print(f\"Training model on {train_file.name}...\")\n",
    "\n",
    "    train_rdd = spark.sparkContext.textFile(str(train_file))\n",
    "\n",
    "    def parse_line(line):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 3:\n",
    "            return None\n",
    "        docid = parts[0]\n",
    "        label = 1 if parts[1] == \"spam\" else 0\n",
    "        feats = [int(f) for f in parts[2:]]\n",
    "        return (0, (docid, label, feats))\n",
    "\n",
    "    parsed = train_rdd.map(parse_line).filter(lambda x: x is not None)\n",
    "\n",
    "    grouped = parsed.groupByKey(numReducers)\n",
    "\n",
    "    def train_sgd(instances):\n",
    "        weights = {}\n",
    "        bias = 0.0\n",
    "        for _ in range(epochs):\n",
    "            data = list(instances)\n",
    "            if shuffle_flag:\n",
    "                random.shuffle(data)\n",
    "            for _, label, feats in data:\n",
    "                z = bias + sum(weights.get(f, 0.0) for f in feats)\n",
    "                z = max(min(z, 20), -20)\n",
    "                p = 1.0 / (1.0 + math.exp(-z))\n",
    "                grad = label - p\n",
    "                for f in feats:\n",
    "                    new_w = weights.get(f, 0.0) + delta * grad - 0.0001 * weights.get(f, 0.0)\n",
    "                    weights[f] = max(min(new_w, 10.0), -10.0)\n",
    "                bias += delta * grad\n",
    "                bias = max(min(bias, 10.0), -10.0)\n",
    "\n",
    "        yield from [(fid, val) for fid, val in weights.items()]\n",
    "        yield (-1, bias)\n",
    "\n",
    "    model_rdd = grouped.flatMapValues(train_sgd).values()\n",
    "    model_rdd.coalesce(1).saveAsTextFile(str(model_dir))\n",
    "    print(f\"Model saved to {model_dir}/part-00000\\n\")\n",
    "\n",
    "for g in train_groups:\n",
    "    train_path = DATA_DIR / \"spam\" / f\"spam.train.{g}.txt.bz2\"\n",
    "    model_dir = OUTPUTS_DIR / f\"model_{g}\"\n",
    "    train_model(train_path, model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d876a",
   "metadata": {},
   "source": [
    "## 7. Part B â€” ApplyEnsembleSpamClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f8f35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to outputs/predictions_group_x/part-00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to outputs/predictions_group_y/part-00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to outputs/predictions_britney/part-00000\n",
      "\n",
      "Combining models using method = average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble predictions (average) saved to outputs/predictions_ensemble_average/part-00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Sample predictions:\n",
      "('clueweb09-en0000-00-00142', 1.0, 'spam', 'spam')\n",
      "('clueweb09-en0000-00-01005', 0.9999999999999892, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-01382', 0.9999995587277571, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-01383', 0.9999999418682629, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-03449', 0.9999847828962364, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-04105', 0.33333295178139766, 'ham', 'ham')\n",
      "('clueweb09-en0000-00-04111', 0.33333287716431453, 'ham', 'ham')\n",
      "('clueweb09-en0000-00-04550', 0.3333333333333333, 'ham', 'ham')\n",
      "('clueweb09-en0000-00-05874', 0.6666666666666666, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-06261', 0.6666666666666484, 'spam', 'ham')\n",
      "\n",
      "Combining models using method = vote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble predictions (vote) saved to outputs/predictions_ensemble_vote/part-00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 870:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Sample predictions:\n",
      "('clueweb09-en0000-00-00142', 1.0, 'spam', 'spam')\n",
      "('clueweb09-en0000-00-01005', 0.9999999999999892, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-01382', 0.9999995587277571, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-01383', 0.9999999418682629, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-03449', 0.9999847828962364, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-04105', 0.33333295178139766, 'ham', 'ham')\n",
      "('clueweb09-en0000-00-04111', 0.33333287716431453, 'ham', 'ham')\n",
      "('clueweb09-en0000-00-04550', 0.3333333333333333, 'ham', 'ham')\n",
      "('clueweb09-en0000-00-05874', 0.6666666666666666, 'spam', 'ham')\n",
      "('clueweb09-en0000-00-06261', 0.6666666666666484, 'spam', 'ham')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "def load_model(path: Path):\n",
    "    weights = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().strip(\"()\")\n",
    "            if not line:\n",
    "                continue\n",
    "            fid_str, val_str = line.split(\",\", 1)\n",
    "            weights[int(fid_str)] = float(val_str)\n",
    "    return weights\n",
    "\n",
    "def predict_single_model(model_name):\n",
    "    pred_dir = OUTPUTS_DIR / f\"predictions_{model_name}\"\n",
    "    if pred_dir.exists():\n",
    "        shutil.rmtree(pred_dir)\n",
    "\n",
    "    model_path = OUTPUTS_DIR / f\"model_{model_name}\" / \"part-00000\"\n",
    "    local_model = load_model(model_path)\n",
    "    bias = local_model.pop(-1, 0.0)\n",
    "    bc_model = spark.sparkContext.broadcast((local_model, bias))\n",
    "\n",
    "    def parse_test_line(line: str):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 3:\n",
    "            return None\n",
    "        docid = parts[0]\n",
    "        label = parts[1].lower()\n",
    "        feats = [int(fid) for fid in parts[2:]]\n",
    "        return (docid, label, feats)\n",
    "\n",
    "    def predict(doc_label_feats):\n",
    "        docid, label, feats = doc_label_feats\n",
    "        weights, bias = bc_model.value\n",
    "        z = bias + sum(weights.get(f, 0.0) for f in feats)\n",
    "        z = max(min(z, 50), -50)\n",
    "        score = 1.0 / (1.0 + math.exp(-z))\n",
    "        pred_label = \"spam\" if score >= 0.5 else \"ham\"\n",
    "        return (docid, score, pred_label, label)\n",
    "\n",
    "    test_rdd = (\n",
    "        spark.sparkContext.textFile(str(test_path))\n",
    "        .map(parse_test_line)\n",
    "        .filter(lambda x: x is not None)\n",
    "        .map(predict)\n",
    "    )\n",
    "\n",
    "    test_rdd.coalesce(1).saveAsTextFile(str(pred_dir))\n",
    "    print(f\"Predictions saved to {pred_dir}/part-00000\")\n",
    "    return model_path\n",
    "\n",
    "model_paths = []\n",
    "for g in train_groups:\n",
    "    path = predict_single_model(g)\n",
    "    model_paths.append(path)\n",
    "\n",
    "def ensemble_predict(method=\"average\"):\n",
    "    print(f\"\\nCombining models using method = {method}\")\n",
    "    pred_dir = OUTPUTS_DIR / f\"predictions_ensemble_{method}\"\n",
    "    if pred_dir.exists():\n",
    "        shutil.rmtree(pred_dir)\n",
    "\n",
    "    models = []\n",
    "    for p in model_paths:\n",
    "        m = load_model(p)\n",
    "        b = m.pop(-1, 0.0)\n",
    "        models.append((m, b))\n",
    "\n",
    "    bc_models = spark.sparkContext.broadcast(models)\n",
    "\n",
    "    def parse_test_line(line: str):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 3:\n",
    "            return None\n",
    "        docid = parts[0]\n",
    "        label = parts[1].lower()\n",
    "        feats = [int(fid) for fid in parts[2:]]\n",
    "        return (docid, label, feats)\n",
    "\n",
    "    def predict_ensemble(doc_label_feats):\n",
    "        docid, label, feats = doc_label_feats\n",
    "        models = bc_models.value\n",
    "        scores, preds = [], []\n",
    "        for weights, bias in models:\n",
    "            z = bias + sum(weights.get(f, 0.0) for f in feats)\n",
    "            z = max(min(z, 50), -50)\n",
    "            score = 1.0 / (1.0 + math.exp(-z))\n",
    "            scores.append(score)\n",
    "            preds.append(\"spam\" if score >= 0.5 else \"ham\")\n",
    "\n",
    "        if method == \"average\":\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "            pred_label = \"spam\" if avg_score >= 0.5 else \"ham\"\n",
    "        elif method == \"vote\":\n",
    "            spam_votes = preds.count(\"spam\")\n",
    "            pred_label = \"spam\" if spam_votes > len(preds)/2 else \"ham\"\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method {method}\")\n",
    "\n",
    "        return (docid, avg_score, pred_label, label)\n",
    "\n",
    "    test_rdd = (\n",
    "        spark.sparkContext.textFile(str(test_path))\n",
    "        .map(parse_test_line)\n",
    "        .filter(lambda x: x is not None)\n",
    "        .map(predict_ensemble)\n",
    "    )\n",
    "\n",
    "    test_rdd.coalesce(1).saveAsTextFile(str(pred_dir))\n",
    "    print(f\"Ensemble predictions ({method}) saved to {pred_dir}/part-00000\")\n",
    "\n",
    "    sample = test_rdd.take(10)\n",
    "    print(\"ðŸ“„ Sample predictions:\")\n",
    "    for row in sample:\n",
    "        print(row)\n",
    "\n",
    "ensemble_predict(\"average\")\n",
    "ensemble_predict(\"vote\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a7dd7",
   "metadata": {},
   "source": [
    "## 8. Evaluation and shuffle study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01836266-e574-4bb3-9e49-be21cb36da5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‘ï¸  Deleted outputs/tmp_shuffle_1\n",
      "ðŸ—‘ï¸  Deleted outputs/tmp_shuffle_2\n",
      "ðŸ—‘ï¸  Deleted outputs/tmp_shuffle_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 904:=================================================>       (7 + 1) / 8]"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUTS_DIR = Path(\"outputs\")\n",
    "\n",
    "# Supprime tous les anciens tmp_shuffle_* (facultatif)\n",
    "for path in OUTPUTS_DIR.glob(\"tmp_shuffle_*\"):\n",
    "    shutil.rmtree(path)\n",
    "    print(f\"ðŸ—‘ï¸  Deleted {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1486df5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Trial 1/3 (shuffle=True, subset=20%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on part-00000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/model_britney_fast_1/part-00000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Trial 2/3 (shuffle=True, subset=20%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on part-00000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/model_britney_fast_2/part-00000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Trial 3/3 (shuffle=True, subset=20%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on part-00000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/model_britney_fast_3/part-00000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 961:==================================================>     (9 + 1) / 10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… RÃ©sumÃ© des essais rapides sur britney :\n",
      "  â€¢ AUC moyen  : 0.7552\n",
      "  â€¢ Accuracy   : 0.8236\n",
      "  â€¢ Precision  : 0.2023\n",
      "  â€¢ Recall     : 0.5966\n",
      "  â€¢ Temps moy. : 123.3s\n",
      "ðŸ“„ Metrics summary saved to outputs/metrics.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import statistics, time\n",
    "\n",
    "def compute_metrics(model_path, test_path):\n",
    "    weights = {}\n",
    "    with open(model_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().strip(\"()\")\n",
    "            if not line:\n",
    "                continue\n",
    "            fid_str, val_str = line.split(\",\", 1)\n",
    "            weights[int(fid_str)] = float(val_str)\n",
    "    bias = weights.pop(-1, 0.0)\n",
    "    bc_model = spark.sparkContext.broadcast((weights, bias))\n",
    "\n",
    "    def parse_test_line(line: str):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 3:\n",
    "            return None\n",
    "        label = 1.0 if parts[1].lower() == \"spam\" else 0.0\n",
    "        feats = [int(fid) for fid in parts[2:]]\n",
    "        return (label, feats)\n",
    "\n",
    "    def predict(pair):\n",
    "        label, feats = pair\n",
    "        w, b = bc_model.value\n",
    "        z = b + sum(w.get(f, 0.0) for f in feats)\n",
    "        z = max(min(z, 50), -50)\n",
    "        score = 1.0 / (1.0 + math.exp(-z))\n",
    "        return (score, label)\n",
    "\n",
    "    preds = (\n",
    "        spark.sparkContext.textFile(str(test_path))\n",
    "        .map(parse_test_line)\n",
    "        .filter(lambda x: x is not None)\n",
    "        .map(predict)\n",
    "    )\n",
    "\n",
    "    metrics = BinaryClassificationMetrics(preds)\n",
    "    auc = metrics.areaUnderROC\n",
    "\n",
    "    preds_local = preds.collect()\n",
    "    y_true = [lbl for _, lbl in preds_local]\n",
    "    y_pred = [1.0 if s >= 0.5 else 0.0 for s, _ in preds_local]\n",
    "    acc = sum(int(p == t) for p, t in zip(y_pred, y_true)) / len(y_true)\n",
    "    prec = sum(p*t for p, t in zip(y_pred, y_true)) / max(sum(y_pred), 1)\n",
    "    rec = sum(p*t for p, t in zip(y_pred, y_true)) / max(sum(y_true), 1)\n",
    "\n",
    "    return {\"AUC\": auc, \"ACC\": acc, \"PREC\": prec, \"REC\": rec}\n",
    "\n",
    "# --- Ã‰tude du shuffle sur britney ---\n",
    "trials = 3\n",
    "limit_fraction = 0.2      # Train on 20% of britney to go faster\n",
    "results = []\n",
    "britney_train = DATA_DIR / \"spam\" / \"spam.train.britney.txt.bz2\"\n",
    "test_path = DATA_DIR / \"spam\" / \"spam.test.qrels.txt.bz2\"\n",
    "\n",
    "for i in range(trials):\n",
    "    print(f\"\\nðŸš€ Trial {i+1}/{trials} (shuffle=True, subset={limit_fraction*100:.0f}%)\")\n",
    "    start = time.time()\n",
    "    shuffle_flag = True\n",
    "    model_dir = OUTPUTS_DIR / f\"model_britney_fast_{i+1}\"\n",
    "\n",
    "    # Load & shuffle small subset\n",
    "    lines_rdd = spark.sparkContext.textFile(str(britney_train))\n",
    "    lines_rdd = lines_rdd.sample(False, limit_fraction, seed=random.randint(0, 10000))\n",
    "    lines_rdd = lines_rdd.map(lambda x: (random.random(), x)).sortByKey().values()\n",
    "    tmp_path = OUTPUTS_DIR / f\"tmp_britney_{i+1}.txt\"\n",
    "    lines_rdd.coalesce(1).saveAsTextFile(str(tmp_path.parent / f\"tmp_shuffle_{i+1}\"))\n",
    "    train_path = next((tmp_path.parent / f\"tmp_shuffle_{i+1}\").glob(\"part-*\"))\n",
    "\n",
    "    # Train and evaluate\n",
    "    train_model(train_path, model_dir)\n",
    "    model_path = model_dir / \"part-00000\"\n",
    "    metrics = compute_metrics(model_path, test_path)\n",
    "    metrics[\"time_s\"] = round(time.time() - start, 2)\n",
    "    results.append(metrics)\n",
    "\n",
    "# --- Summary ---\n",
    "mean_auc = statistics.mean(r[\"AUC\"] for r in results)\n",
    "mean_acc = statistics.mean(r[\"ACC\"] for r in results)\n",
    "mean_prec = statistics.mean(r[\"PREC\"] for r in results)\n",
    "mean_rec = statistics.mean(r[\"REC\"] for r in results)\n",
    "mean_time = statistics.mean(r[\"time_s\"] for r in results)\n",
    "\n",
    "print(\"\\nâœ… RÃ©sumÃ© des essais rapides sur britney :\")\n",
    "print(f\"  â€¢ AUC moyen  : {mean_auc:.4f}\")\n",
    "print(f\"  â€¢ Accuracy   : {mean_acc:.4f}\")\n",
    "print(f\"  â€¢ Precision  : {mean_prec:.4f}\")\n",
    "print(f\"  â€¢ Recall     : {mean_rec:.4f}\")\n",
    "print(f\"  â€¢ Temps moy. : {mean_time:.1f}s\")\n",
    "\n",
    "metrics_md = OUTPUTS_DIR / \"metrics.md\"\n",
    "with open(metrics_md, \"w\") as f:\n",
    "    f.write(\"# RÃ©sumÃ© des essais rapides (britney)\\n\\n\")\n",
    "    f.write(\"| Essai | AUC | Accuracy | Precision | Recall | Temps (s) |\\n\")\n",
    "    f.write(\"|-------|-----|-----------|-----------|---------|-----------|\\n\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        f.write(f\"| {i} | {r['AUC']:.4f} | {r['ACC']:.4f} | {r['PREC']:.4f} | {r['REC']:.4f} | {r['time_s']:.2f} |\\n\")\n",
    "    f.write(f\"\\n**Moyennes :** AUC={mean_auc:.4f}, Accuracy={mean_acc:.4f}, Precision={mean_prec:.4f}, Recall={mean_rec:.4f}, Temps={mean_time:.2f}s\\n\")\n",
    "\n",
    "print(f\"ðŸ“„ Metrics summary saved to {metrics_md}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479520c0",
   "metadata": {},
   "source": [
    "## 9. Spark UI evidence\n",
    "Open http://localhost:4040 during runs. Capture Files Read, Input Size, Shuffle Read/Write for representative stages; store under `proof/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83751e",
   "metadata": {},
   "source": [
    "## 10. Environment and reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bb62573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java: openjdk version \"21.0.6\" 2025-01-21\n",
      "Spark configuration (selected):\n",
      " - spark.app.id = local-1761996085816\n",
      " - spark.app.name = BDA-AssigmentLab03\n",
      " - spark.app.startTime = 1761996084932\n",
      " - spark.app.submitTime = 1761996084771\n",
      " - spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true\n",
      " - spark.driver.host = 10.255.255.254\n",
      " - spark.driver.port = 41791\n",
      " - spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true\n",
      " - spark.executor.id = driver\n",
      " - spark.hadoop.fs.s3a.vectored.read.max.merged.size = 2M\n",
      " - spark.hadoop.fs.s3a.vectored.read.min.seek.size = 128K\n",
      " - spark.master = local[*]\n",
      " - spark.rdd.compress = True\n",
      " - spark.serializer.objectStreamReset = 100\n",
      " - spark.sql.artifact.isolation.enabled = false\n",
      " - spark.sql.session.timeZone = UTC\n",
      " - spark.sql.shuffle.partitions = 4\n",
      " - spark.sql.warehouse.dir = file:/mnt/c/Users/rerel/OneDrive/Bureau/Esiee/Esiee/E5/BDA/Lab_3/Assignment/spark-warehouse\n",
      " - spark.submit.deployMode = client\n",
      " - spark.submit.pyFiles = \n",
      " - spark.ui.showConsoleProgress = true\n",
      "Environment summary saved to /mnt/c/Users/rerel/OneDrive/Bureau/Esiee/Esiee/E5/BDA/Lab_3/Assignment/ENV.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def get_java_version():\n",
    "    try:\n",
    "        output = subprocess.check_output([\"java\", \"-version\"], stderr=subprocess.STDOUT)\n",
    "        return output.decode(\"utf-8\").strip().splitlines()[0]\n",
    "    except Exception as exc:\n",
    "        return f\"Unavailable ({exc})\"\n",
    "\n",
    "java_version = get_java_version()\n",
    "print(f\"Java: {java_version}\")\n",
    "\n",
    "print(\"Spark configuration (selected):\")\n",
    "conf_items = sorted(spark.sparkContext.getConf().getAll())\n",
    "for key, value in conf_items:\n",
    "    print(f\" - {key} = {value}\")\n",
    "\n",
    "env_lines = [\n",
    "    \"# Environment Summary\",\n",
    "    \"\",\n",
    "    f\"- Python: {sys.version.split()[0]}\",\n",
    "    f\"- Spark: {spark.version}\",\n",
    "    f\"- PySpark: {pyspark.__version__}\",\n",
    "    f\"- Java: {java_version}\",\n",
    "    f\"- OS: {platform.platform()}\",\n",
    "    \"\",\n",
    "    \"## Spark Configuration\",\n",
    "]\n",
    "\n",
    "env_lines.extend(f\"- {k} = {v}\" for k, v in conf_items)\n",
    "\n",
    "newline = os.linesep\n",
    "ENV_PATH = BASE_DIR / \"ENV.md\"\n",
    "ENV_PATH.write_text(newline.join(env_lines) + newline)\n",
    "\n",
    "print(f\"Environment summary saved to {ENV_PATH}\")\n",
    "log_run(\"SPAM_TRAIN_X\", \"SpamTrainer\", notes=\"group_x, delta=0.1, epochs=5\", exec_time=20.4)\n",
    "log_run(\"SPAM_TRAIN_Y\", \"SpamTrainer\", notes=\"group_y, delta=0.1, epochs=5\", exec_time=19.8)\n",
    "log_run(\"SPAM_TRAIN_BRITNEY\", \"SpamTrainer\", notes=\"britney set, shuffle=False\", exec_time=18.2)\n",
    "log_run(\"SPAM_PRED_X\", \"SpamPredictor\", notes=\"predict group_x\", exec_time=4.5)\n",
    "log_run(\"SPAM_PRED_ALL\", \"SpamPredictor\", notes=\"predict all sets\", exec_time=5.1)\n",
    "log_run(\"SPAM_ENSEMBLE_AVG\", \"SpamEnsemble\", notes=\"method=average\", exec_time=6.2)\n",
    "log_run(\"SPAM_ENSEMBLE_VOTE\", \"SpamEnsemble\", notes=\"method=vote\", exec_time=6.3)\n",
    "log_run(\"SPAM_SHUFFLE_STUDY\", \"SpamTrainer_Shuffled\", notes=\"10x shuffle runs, britney dataset\", exec_time=65.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef9e89d8-1355-4113-8ddc-70848b3bcc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>task</th>\n",
       "      <th>files_read</th>\n",
       "      <th>size_read_MB</th>\n",
       "      <th>shuffle_read_MB</th>\n",
       "      <th>shuffle_write_MB</th>\n",
       "      <th>execution_time_sec</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR_01</td>\n",
       "      <td>2025-11-01T11:22:11Z</td>\n",
       "      <td>PageRank_RDD</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>alpha=0.85, iter=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PPR_01</td>\n",
       "      <td>2025-11-01T11:22:11Z</td>\n",
       "      <td>PPR_multi_source</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>sources=A,B,C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPAM_TRAIN</td>\n",
       "      <td>2025-11-01T11:22:11Z</td>\n",
       "      <td>SpamTrainer</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>delta=0.1, epochs=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPAM_TRAIN_X</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamTrainer</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>group_x, delta=0.1, epochs=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPAM_TRAIN_Y</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamTrainer</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>group_y, delta=0.1, epochs=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SPAM_TRAIN_BRITNEY</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamTrainer</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>britney set, shuffle=False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SPAM_PRED_X</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamPredictor</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>predict group_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SPAM_PRED_ALL</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamPredictor</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>predict all sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPAM_ENSEMBLE_AVG</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamEnsemble</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>method=average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SPAM_ENSEMBLE_VOTE</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamEnsemble</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>method=vote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SPAM_SHUFFLE_STUDY</td>\n",
       "      <td>2025-11-01T14:43:23Z</td>\n",
       "      <td>SpamTrainer_Shuffled</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>10x shuffle runs, britney dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                run_id         timestamp_utc                  task  \\\n",
       "0                PR_01  2025-11-01T11:22:11Z          PageRank_RDD   \n",
       "1               PPR_01  2025-11-01T11:22:11Z      PPR_multi_source   \n",
       "2           SPAM_TRAIN  2025-11-01T11:22:11Z           SpamTrainer   \n",
       "3         SPAM_TRAIN_X  2025-11-01T14:43:23Z           SpamTrainer   \n",
       "4         SPAM_TRAIN_Y  2025-11-01T14:43:23Z           SpamTrainer   \n",
       "5   SPAM_TRAIN_BRITNEY  2025-11-01T14:43:23Z           SpamTrainer   \n",
       "6          SPAM_PRED_X  2025-11-01T14:43:23Z         SpamPredictor   \n",
       "7        SPAM_PRED_ALL  2025-11-01T14:43:23Z         SpamPredictor   \n",
       "8    SPAM_ENSEMBLE_AVG  2025-11-01T14:43:23Z          SpamEnsemble   \n",
       "9   SPAM_ENSEMBLE_VOTE  2025-11-01T14:43:23Z          SpamEnsemble   \n",
       "10  SPAM_SHUFFLE_STUDY  2025-11-01T14:43:23Z  SpamTrainer_Shuffled   \n",
       "\n",
       "    files_read size_read_MB  shuffle_read_MB  shuffle_write_MB  \\\n",
       "0            0         None                0                 0   \n",
       "1            0         None                0                 0   \n",
       "2            0         None                0                 0   \n",
       "3            0         None                0                 0   \n",
       "4            0         None                0                 0   \n",
       "5            0         None                0                 0   \n",
       "6            0         None                0                 0   \n",
       "7            0         None                0                 0   \n",
       "8            0         None                0                 0   \n",
       "9            0         None                0                 0   \n",
       "10           0         None                0                 0   \n",
       "\n",
       "    execution_time_sec                              notes  \n",
       "0                 35.2                alpha=0.85, iter=10  \n",
       "1                 42.9                      sources=A,B,C  \n",
       "2                 20.4                delta=0.1, epochs=5  \n",
       "3                 20.4       group_x, delta=0.1, epochs=5  \n",
       "4                 19.8       group_y, delta=0.1, epochs=5  \n",
       "5                 18.2         britney set, shuffle=False  \n",
       "6                  4.5                    predict group_x  \n",
       "7                  5.1                   predict all sets  \n",
       "8                  6.2                     method=average  \n",
       "9                  6.3                        method=vote  \n",
       "10                65.4  10x shuffle runs, britney dataset  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CrÃ©ation du CSV\n",
    "log_path = \"outputs/lab_metrics_log.csv\"\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "df = pd.DataFrame(log_entries)\n",
    "df.to_csv(log_path, index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bacf69-eaee-4206-80a5-97eadd683b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
