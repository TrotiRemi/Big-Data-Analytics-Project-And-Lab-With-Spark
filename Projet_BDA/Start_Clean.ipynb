{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c893e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 4: ML DATA PREPARATION\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, Imputer\n",
    "from pyspark.sql.functions import col, year, expr, randn, abs as spark_abs\n",
    "\n",
    "print('\\\\n' + '='*70)\n",
    "print('PHASE 4: ML DATA PREPARATION')\n",
    "print('='*70)\n",
    "\n",
    "feature_cols = [\n",
    "    'hourly_return', 'hl_range', 'close_ma_24h', 'close_ma_7d', 'volatility_24h', 'volume_ratio',\n",
    "    'tx_count', 'tx_count_ratio', 'total_volume_btc', 'volume_btc_ratio',\n",
    "    'avg_inputs_log', 'avg_outputs_log', 'price_to_onchain', 'io_ratio'\n",
    "]\n",
    "\n",
    "print(f'\\\\nFeatures: {len(feature_cols)} total')\n",
    "df_features_filtered = df_features.filter(col('tx_count').isNotNull())\n",
    "print(f'Rows with blockchain: {df_features_filtered.count()}')\n",
    "\n",
    "if df_features_filtered.count() > 0:\n",
    "    df_ml = df_features_filtered\n",
    "    print('Using REAL blockchain data')\n",
    "else:\n",
    "    print('NO OVERLAP - Using synthetic fallback')\n",
    "    df_ml = df_features.filter(col('price_direction').isNotNull())\n",
    "    df_ml = df_ml.withColumn('tx_count', spark_abs(expr('cast(randn(42) * 500 + 1000 as double)')))\n",
    "    df_ml = df_ml.withColumn('tx_count_ratio', expr('tx_count / 1000.0'))\n",
    "    df_ml = df_ml.withColumn('total_volume_btc', spark_abs(expr('randn(43) * 100 + 200')))\n",
    "    df_ml = df_ml.withColumn('volume_btc_ratio', expr('total_volume_btc / 200.0'))\n",
    "    df_ml = df_ml.withColumn('avg_inputs_log', expr('log1p(abs(randn(44) * 1 + 2))'))\n",
    "    df_ml = df_ml.withColumn('avg_outputs_log', expr('log1p(abs(randn(45) * 1 + 2))'))\n",
    "    df_ml = df_ml.withColumn('price_to_onchain', expr('Close / (total_volume_btc + 1)'))\n",
    "    df_ml = df_ml.withColumn('io_ratio', expr('exp(avg_inputs_log) / (exp(avg_outputs_log) + 0.1)'))\n",
    "\n",
    "imputer = Imputer(inputCols=feature_cols, outputCols=feature_cols, strategy='median')\n",
    "df_ml = imputer.fit(df_ml).transform(df_ml)\n",
    "df_ml = df_ml.filter(col('price_direction').isNotNull())\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features_raw', handleInvalid='skip')\n",
    "df_ml = assembler.transform(df_ml)\n",
    "\n",
    "scaler = StandardScaler(inputCol='features_raw', outputCol='features', withMean=True, withStd=True)\n",
    "df_ml = scaler.fit(df_ml).transform(df_ml)\n",
    "\n",
    "df_ml = df_ml.withColumn('year', year('Open time'))\n",
    "df_train = df_ml.filter(col('year') < 2024)\n",
    "df_test = df_ml.filter(col('year') >= 2024)\n",
    "\n",
    "print(f'Train: {df_train.count()} rows (2018-2023)')\n",
    "print(f'Test: {df_test.count()} rows (2024-2025)')\n",
    "print('PHASE 4 COMPLETE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 5: MODEL TRAINING\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "print('\\\\n' + '='*70)\n",
    "print('PHASE 5: MODEL TRAINING')\n",
    "print('='*70)\n",
    "\n",
    "lr = LogisticRegression(labelCol='price_direction', featuresCol='features', maxIter=100, regParam=0.01)\n",
    "model_lr = lr.fit(df_train)\n",
    "pred_lr = model_lr.transform(df_test)\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='price_direction', featuresCol='features', numTrees=50, maxDepth=10, seed=42)\n",
    "model_rf = rf.fit(df_train)\n",
    "pred_rf = model_rf.transform(df_test)\n",
    "\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='price_direction', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol='price_direction', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "auc_lr = evaluator_auc.evaluate(pred_lr)\n",
    "acc_lr = evaluator_acc.evaluate(pred_lr)\n",
    "auc_rf = evaluator_auc.evaluate(pred_rf)\n",
    "acc_rf = evaluator_acc.evaluate(pred_rf)\n",
    "\n",
    "print(f'\\\\nLogistic Regression - AUC: {auc_lr:.4f}, Accuracy: {acc_lr:.4f}')\n",
    "print(f'Random Forest - AUC: {auc_rf:.4f}, Accuracy: {acc_rf:.4f}')\n",
    "print(f'\\\\nBest Model: {\"Random Forest\" if auc_rf > auc_lr else \"Logistic Regression\"} (AUC: {max(auc_rf, auc_lr):.4f})')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
